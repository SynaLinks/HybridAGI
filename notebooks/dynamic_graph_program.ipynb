{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Graph Program\n",
    "\n",
    "In this notebook we are going to explore the dynamic calls of programs. This feature is particurly important for learning systems and systems with an extensive range of capabilities. If your system have a wide range of capabilities, choosing the one to use in the main program will likely to be impractical because each decision will add latency to your program. In that case, it is better to work with dynamic programs.\n",
    "\n",
    "### Protected programs\n",
    "\n",
    "When experimenting with dynamic calls, one important feature of HybridAGI is the fact that we use the dependency graph of HybridAGI to protect the main prompting mechanism that usually contains the safety and learning algorithm of your system. Which means that the system cannot read/search or modify any program that the `main` program depends on (including itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoan/.cache/pypoetry/virtualenvs/hybridagi-B1GoJrSC-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// @desc: The main program\n",
      "CREATE\n",
      "// Nodes declaration\n",
      "(start:Control {id: \"start\"}),\n",
      "(end:Control {id: \"end\"}),\n",
      "(fulfill_objective:Program {\n",
      "  id: \"fulfill_objective\",\n",
      "  purpose: \"Fulfill the objective\",\n",
      "  program: \"fulfill_objective\"\n",
      "}),\n",
      "// Structure declaration\n",
      "(start)-[:NEXT]->(fulfill_objective),\n",
      "(fulfill_objective)-[:NEXT]->(end)\n"
     ]
    }
   ],
   "source": [
    "import hybridagi.core.graph_program as gp\n",
    "\n",
    "main = gp.GraphProgram(\n",
    "    name = \"main\",\n",
    "    description = \"The main program\",\n",
    ")\n",
    "\n",
    "main.add(gp.Program(\n",
    "    id = \"fulfill_objective\",\n",
    "    purpose = \"Fulfill the objective\",\n",
    "    program = \"fulfill_objective\",\n",
    "))\n",
    "\n",
    "main.connect(\"start\", \"fulfill_objective\")\n",
    "main.connect(\"fulfill_objective\", \"end\")\n",
    "\n",
    "main.build()\n",
    "\n",
    "main.save(\"data/programs\") # We save it into the folder data/programs\n",
    "\n",
    "print(main)\n",
    "\n",
    "fulfill_objective = gp.GraphProgram(\n",
    "    name = \"fulfill_objective\",\n",
    "    description = \"Try to call an existing program to fulfill the objective\",\n",
    ")\n",
    "\n",
    "fulfill_objective.add(gp.Action(\n",
    "    id = \"program_search\",\n",
    "    purpose = \"Search for relevant routines to fullfil the Objective\",\n",
    "    tool = \"GraphProgramSearch\",\n",
    "    prompt = \"Use the Objective to describe in ONE short sentence the action to take\",\n",
    "))\n",
    "\n",
    "fulfill_objective.add(gp.Decision(\n",
    "    id = \"is_routine_known\",\n",
    "    purpose = \"Check if the routine to fulfill the objective is in the previous search\",\n",
    "    question = \"Is the routine to fulfill the objective in the above search? If you don't know consider the most probable\",\n",
    "))\n",
    "\n",
    "fulfill_objective.add(gp.Action(\n",
    "    id = \"call_routine\",\n",
    "    purpose = \"Pick the most appropriate routine from your context\",\n",
    "    tool = \"CallGraphProgram\",\n",
    "    prompt = \"\"\"\n",
    "Use the context to known which routine to pick.\n",
    "Only infer the name of the program without addtionnal details.\n",
    "Make sure to give only ONE routine name. \n",
    "If you don't know which one to pick, try the one with less assumptions.\n",
    "\"\"\",\n",
    "))\n",
    "\n",
    "fulfill_objective.connect(\"start\", \"program_search\")\n",
    "fulfill_objective.connect(\"program_search\", \"is_routine_known\")\n",
    "fulfill_objective.connect(\"is_routine_known\", \"call_routine\", label = \"Yes\")\n",
    "fulfill_objective.connect(\"is_routine_known\", \"call_routine\", label = \"Maybe\")\n",
    "fulfill_objective.connect(\"is_routine_known\", \"end\", label = \"No\")\n",
    "fulfill_objective.connect(\"call_routine\", \"end\")\n",
    "\n",
    "fulfill_objective.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// @desc: Search for information and answer\n",
      "CREATE\n",
      "// Nodes declaration\n",
      "(start:Control {id: \"start\"}),\n",
      "(end:Control {id: \"end\"}),\n",
      "(document_search:Action {\n",
      "  id: \"document_search\",\n",
      "  purpose: \"Find relevant documents\",\n",
      "  tool: \"DocumentSearch\",\n",
      "  prompt: \"Please infer the similarity search query (only ONE item) based on the Objective's question\"\n",
      "}),\n",
      "(answer:Action {\n",
      "  id: \"answer\",\n",
      "  purpose: \"Answer the Objective's question\",\n",
      "  tool: \"Speak\",\n",
      "  prompt: \"\\nPlease answer the Objective's question using the relevant documents in your context.\\nIf no document are relevant just say that you don't know.\\nDon't state the Objective's question and only give the correct answer.\\n\"\n",
      "}),\n",
      "// Structure declaration\n",
      "(start)-[:NEXT]->(document_search),\n",
      "(document_search)-[:NEXT]->(answer),\n",
      "(answer)-[:NEXT]->(end)\n"
     ]
    }
   ],
   "source": [
    "# Now let's make some programs to call, first vector only RAG program\n",
    "\n",
    "search = gp.GraphProgram(\n",
    "    name = \"search\",\n",
    "    description = \"Search for information and answer\",\n",
    ")\n",
    "\n",
    "search.add(gp.Action(\n",
    "    id = \"document_search\",\n",
    "    purpose = \"Find relevant documents\",\n",
    "    tool = \"DocumentSearch\",\n",
    "    prompt = \"Please infer the similarity search query (only ONE item) based on the Objective's question\",\n",
    "))\n",
    "\n",
    "search.add(gp.Action(\n",
    "    id = \"answer\",\n",
    "    purpose = \"Answer the Objective's question\",\n",
    "    tool = \"Speak\",\n",
    "    prompt = \"\"\"\n",
    "Please answer the Objective's question using the relevant documents in your context.\n",
    "If no document are relevant just say that you don't know.\n",
    "Don't state the Objective's question and only give the correct answer.\n",
    "\"\"\",\n",
    "))\n",
    "\n",
    "search.connect(\"start\", \"document_search\")\n",
    "search.connect(\"document_search\", \"answer\")\n",
    "search.connect(\"answer\", \"end\")\n",
    "\n",
    "search.build()\n",
    "\n",
    "search.save(\"data/programs\") # We save it into the folder data/programs\n",
    "\n",
    "print(search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tell_joke = gp.GraphProgram(\n",
    "    name = \"tell_joke\",\n",
    "    description = \"Tell a joke to the user\",\n",
    ")\n",
    "\n",
    "tell_joke.add(gp.Action(\n",
    "    id = \"tell_joke\",\n",
    "    purpose = \"Tell a joke\",\n",
    "    tool = \"Speak\",\n",
    "    prompt = \"Imagine that you are the best comedian on earth, please tell your best joke\",\n",
    "))\n",
    "\n",
    "tell_joke.connect(\"start\", \"tell_joke\")\n",
    "tell_joke.connect(\"tell_joke\", \"end\")\n",
    "\n",
    "tell_joke.build()\n",
    "\n",
    "tell_joke.save(\"data/programs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 19.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynamic_program_program_memory.html\n"
     ]
    }
   ],
   "source": [
    "# Now we can embbed them and load them into memory\n",
    "\n",
    "from hybridagi.memory.integration.local import LocalProgramMemory\n",
    "from hybridagi.core.pipeline import Pipeline\n",
    "from hybridagi.core.datatypes import GraphProgramList\n",
    "from hybridagi.embeddings import SentenceTransformerEmbeddings\n",
    "from hybridagi.modules.embedders import GraphProgramEmbedder\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(\n",
    "    model_name_or_path = \"all-MiniLM-L6-v2\",\n",
    "    dim = 384, # The dimention of the embeddings vector (also called dense vector)\n",
    ")\n",
    "\n",
    "prog_pipeline = Pipeline()\n",
    "\n",
    "prog_pipeline.add(\"embed_programs\", GraphProgramEmbedder(embeddings=embeddings))\n",
    "\n",
    "embedded_programs = prog_pipeline(GraphProgramList(progs=[main, fulfill_objective, search, tell_joke]))\n",
    "\n",
    "program_memory = LocalProgramMemory(index_name=\"dynamic_program\")\n",
    "\n",
    "program_memory.update(embedded_programs)\n",
    "\n",
    "program_memory.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 8456.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 80.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Let's add some documents for the RAG program\n",
    "from hybridagi.readers import TextReader\n",
    "from hybridagi.core.pipeline import Pipeline\n",
    "from hybridagi.modules.splitters import DocumentSentenceSplitter\n",
    "from hybridagi.modules.embedders import DocumentEmbedder\n",
    "from hybridagi.memory.integration.local import LocalDocumentMemory\n",
    "\n",
    "reader = TextReader()\n",
    "\n",
    "documents = reader(\"data/SynaLinks_presentation.md\")\n",
    "\n",
    "doc_pipeline = Pipeline()\n",
    "\n",
    "doc_pipeline.add(\"chunk_docs\", DocumentSentenceSplitter())\n",
    "doc_pipeline.add(\"embed_docs\", DocumentEmbedder(\n",
    "    embeddings = embeddings,\n",
    "))\n",
    "\n",
    "embedded_documents = doc_pipeline(documents)\n",
    "\n",
    "document_memory = LocalDocumentMemory(index_name=\"dynamic_program\")\n",
    "\n",
    "document_memory.update(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m--- Step 0 ---\n",
      "Call Program: main\n",
      "Program Purpose: Tell me a joke about neuro-symbolic AI systems\u001b[0m\n",
      "\u001b[35m--- Step 1 ---\n",
      "Call Program: fulfill_objective\n",
      "Program Purpose: Fulfill the objective\u001b[0m\n",
      "\u001b[36m--- Step 2 ---\n",
      "Action Purpose: Search for relevant routines to fullfil the Objective\n",
      "Action: {\n",
      "  \"query\": \"\\\"Find jokes about neuro-symbolic AI systems\\\"\",\n",
      "  \"routines\": [\n",
      "    {\n",
      "      \"name\": \"tell_joke\",\n",
      "      \"description\": \"Tell a joke to the user\",\n",
      "      \"routine\": \"// @desc: Tell a joke to the user\\nCREATE\\n// Nodes declaration\\n(start:Control {id: \\\"start\\\"}),\\n(end:Control {id: \\\"end\\\"}),\\n(tell_joke:Action {\\n  id: \\\"tell_joke\\\",\\n  purpose: \\\"Tell a joke\\\",\\n  tool: \\\"Speak\\\",\\n  prompt: \\\"Imagine that you are the best comedian on earth, please tell your best joke\\\"\\n}),\\n// Structure declaration\\n(start)-[:NEXT]->(tell_joke),\\n(tell_joke)-[:NEXT]->(end)\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"search\",\n",
      "      \"description\": \"Search for information and answer\",\n",
      "      \"routine\": \"// @desc: Search for information and answer\\nCREATE\\n// Nodes declaration\\n(start:Control {id: \\\"start\\\"}),\\n(end:Control {id: \\\"end\\\"}),\\n(document_search:Action {\\n  id: \\\"document_search\\\",\\n  purpose: \\\"Find relevant documents\\\",\\n  tool: \\\"DocumentSearch\\\",\\n  prompt: \\\"Please infer the similarity search query (only ONE item) based on the Objective's question\\\"\\n}),\\n(answer:Action {\\n  id: \\\"answer\\\",\\n  purpose: \\\"Answer the Objective's question\\\",\\n  tool: \\\"Speak\\\",\\n  prompt: \\\"\\\\nPlease answer the Objective's question using the relevant documents in your context.\\\\nIf no document are relevant just say that you don't know.\\\\nDon't state the Objective's question and only give the correct answer.\\\\n\\\"\\n}),\\n// Structure declaration\\n(start)-[:NEXT]->(document_search),\\n(document_search)-[:NEXT]->(answer),\\n(answer)-[:NEXT]->(end)\"\n",
      "    }\n",
      "  ]\n",
      "}\u001b[0m\n",
      "\u001b[34m--- Step 3 ---\n",
      "Decision Purpose: Check if the routine to fulfill the objective is in the previous search\n",
      "Decision Question: Is the routine to fulfill the objective in the above search? If you don't know consider the most probable\n",
      "Decision: MAYBE\u001b[0m\n",
      "\u001b[36m--- Step 4 ---\n",
      "Action Purpose: Pick the most appropriate routine from your context\n",
      "Action: {\n",
      "  \"name\": \"tell_joke\",\n",
      "  \"observation\": \"Successfully called\"\n",
      "}\u001b[0m\n",
      "\u001b[36m--- Step 5 ---\n",
      "Action Purpose: Tell a joke\n",
      "Action: {\n",
      "  \"message\": \"Here is a joke about neuro-symbolic AI systems:\\n\\nWhy did the neuro-symbolic AI system go to therapy?\\n\\nBecause it had a case of multiple personalities! It couldn't decide whether to think like a human or a machine. But don't worry, it's getting better with each session. It's learning to balance its symbolic and connectionist sides, just like a good therapist helps us all do in our daily lives.\"\n",
      "}\u001b[0m\n",
      "\u001b[35m--- Step 6 ---\n",
      "End Program: tell_joke\u001b[0m\n",
      "\u001b[35m--- Step 7 ---\n",
      "End Program: fulfill_objective\u001b[0m\n",
      "\u001b[35m--- Step 8 ---\n",
      "End Program: main\u001b[0m\n",
      "Here is a joke about neuro-symbolic AI systems:\n",
      "\n",
      "Why did the neuro-symbolic AI system go to therapy?\n",
      "\n",
      "Because it had a case of multiple personalities! It couldn't decide whether to think like a human or a machine. But don't worry, it's getting better with each session. It's learning to balance its symbolic and connectionist sides, just like a good therapist helps us all do in our daily lives.\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from hybridagi.modules.agents import GraphInterpreterAgent\n",
    "from hybridagi.core.datatypes import AgentState, Query\n",
    "from hybridagi.modules.agents.tools import (\n",
    "    DocumentSearchTool,\n",
    "    SpeakTool,\n",
    "    CallGraphProgramTool,\n",
    "    GraphProgramSearchTool,\n",
    ")\n",
    "from hybridagi.modules.retrievers.integration.local import FAISSDocumentRetriever, FAISSGraphProgramRetriever\n",
    "\n",
    "agent_state = AgentState()\n",
    "\n",
    "tools = [\n",
    "    SpeakTool(\n",
    "        agent_state = agent_state,\n",
    "    ),\n",
    "    DocumentSearchTool(\n",
    "        retriever = FAISSDocumentRetriever(\n",
    "            document_memory = document_memory,\n",
    "            embeddings = embeddings,\n",
    "            distance = \"cosine\",\n",
    "            max_distance = 0.7,\n",
    "            k = 5,\n",
    "            reranker = None,\n",
    "        ),\n",
    "    ),\n",
    "    GraphProgramSearchTool(\n",
    "        retriever = FAISSGraphProgramRetriever(\n",
    "            program_memory = program_memory,\n",
    "            embeddings = embeddings,\n",
    "            distance = \"cosine\",\n",
    "            max_distance = 0.7,\n",
    "            k = 5,\n",
    "            reranker = None,\n",
    "        ),\n",
    "    ),\n",
    "    CallGraphProgramTool(\n",
    "        agent_state = agent_state,\n",
    "        program_memory = program_memory,\n",
    "    )\n",
    "]\n",
    "\n",
    "agent = GraphInterpreterAgent(\n",
    "    agent_state = agent_state,\n",
    "    program_memory = program_memory,\n",
    "    tools = tools\n",
    ")\n",
    "\n",
    "# We can now setup the LLM using Ollama client from DSPy\n",
    "\n",
    "lm = dspy.OllamaLocal(model='mistral', max_tokens=1024, stop=[\"\\n\\n\\n\"])\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "result = agent(Query(query=\"Tell me a joke about neuro-symbolic AI systems\"))\n",
    "\n",
    "print(result.final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that neither the main progran nor the fullfil objective are present in the search, because they are protected thanks to the dependency graph automatically build."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybridagi-B1GoJrSC-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
