{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Only RAG\n",
    "\n",
    "In this notebook we are going to explore how to make a vector only RAG system. RAG stands for Retrieval Augmented Generation, the basic idea of this technique is to not use the LLM to recall knowledge but instead rely on a external system like a database to provide information to the system.\n",
    "\n",
    "The main advantage of vector-only RAG systems over Knowledge Graph RAG is the fact that you don't need to model your knowledge domain and can use very simple data pipelines. They excel in retrieving information based on the context of the question but fail short in retrieving factual knowledge (you've been warned).\n",
    "\n",
    "In this tutorial we are going to present you a small system that is nice to learn how RAG works in practice. To make things bit more complicated, we are going to start from a PDF file.\n",
    "\n",
    "The PDF we are going to parse is a paper from [Elisabeth Spelke](https://en.wikipedia.org/wiki/Elizabeth_Spelke) a developmental psychologist that studied cognition in infants, culturally different communities and non-human species to understand the fundamental building blocks of our mind. It contains evidences that our cognition system is build upon several key components and is an important inspiration for Neuro-Symbolic and Robotics systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoan/.cache/pypoetry/virtualenvs/hybridagi-B1GoJrSC-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pymupdf # Used to extract the text data from the PDF file\n",
    "from hybridagi.core.datatypes import Document, DocumentList\n",
    "from hybridagi.core.pipeline import Pipeline\n",
    "from hybridagi.embeddings import SentenceTransformerEmbeddings\n",
    "from hybridagi.modules.splitters import DocumentSentenceSplitter\n",
    "from hybridagi.modules.embedders import DocumentEmbedder\n",
    "from hybridagi.readers import PDFReader\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(\n",
    "    model_name_or_path = \"all-MiniLM-L6-v2\",\n",
    "    dim = 384, # The dimention of the embeddings vector (also called dense vector)\n",
    ")\n",
    "\n",
    "reader = PDFReader()\n",
    "\n",
    "input_docs = reader(\"data/SpelkeKinzlerCoreKnowledge.pdf\")\n",
    "\n",
    "# Now that we have our input documents, we can start to make our data processing pipeline\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "pipeline.add(\"first_split\", DocumentSentenceSplitter(\n",
    "    method = \"word\",\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 0,\n",
    "    separator = \" \",\n",
    "))\n",
    "pipeline.add(\"second_split\", DocumentSentenceSplitter(\n",
    "    method = \"word\",\n",
    "    chunk_size = 30,\n",
    "    chunk_overlap = 0,\n",
    "    separator = \" \",\n",
    "))\n",
    "pipeline.add(\"embed_chunks\", DocumentEmbedder(embeddings=embeddings))\n",
    "\n",
    "output_docs = pipeline(input_docs)\n",
    "intermediate_docs = pipeline.get_output(\"first_split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the documents into memory\n",
    "\n",
    "Now that we have our documents we can load them into memory, for storing unstructured textual documents, we provide the `DocumentMemory` and for this example we are going to use the local integration for rapid prototyping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_rag_agent_document_memory.html\n"
     ]
    }
   ],
   "source": [
    "from hybridagi.memory.integration.local import LocalDocumentMemory\n",
    "\n",
    "document_memory = LocalDocumentMemory(index_name=\"vector_rag_agent\")\n",
    "\n",
    "document_memory.update(input_docs)\n",
    "document_memory.update(intermediate_docs)\n",
    "document_memory.update(output_docs)\n",
    "\n",
    "document_memory.show() # Let's see what the memory look like now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a RAG Agent\n",
    "\n",
    "Now that our data is ready and loaded into memory, we can start making our RAG Agent, but first we need to create our graph program that is going to encode the Agent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// @desc: The main program\n",
      "CREATE\n",
      "// Nodes declaration\n",
      "(start:Control {id: \"start\"}),\n",
      "(end:Control {id: \"end\"}),\n",
      "(document_search:Action {\n",
      "  id: \"document_search\",\n",
      "  purpose: \"Find relevant documents\",\n",
      "  tool: \"DocumentSearch\",\n",
      "  prompt: \"Please infer the similarity search query (only ONE item) based on the Objective's question\"\n",
      "}),\n",
      "(answer:Action {\n",
      "  id: \"answer\",\n",
      "  purpose: \"Answer the Objective's question\",\n",
      "  tool: \"Speak\",\n",
      "  prompt: \"\\nPlease answer the Objective's question using the relevant documents in your context.\\nIf no document are relevant just say that you don't know.\\nDon't state the Objective's question and only give the correct answer.\\n\"\n",
      "}),\n",
      "// Structure declaration\n",
      "(start)-[:NEXT]->(document_search),\n",
      "(document_search)-[:NEXT]->(answer),\n",
      "(answer)-[:NEXT]->(end)\n"
     ]
    }
   ],
   "source": [
    "import hybridagi.core.graph_program as gp\n",
    "\n",
    "# We first need to program our RAG Agent using Graph Prompt Programs\n",
    "# Here we have the simplest agent possible that involve 2 steps\n",
    "# It first retrieve documents, then answer to the objective's question based on them\n",
    "\n",
    "main = gp.GraphProgram(\n",
    "    name = \"main\",\n",
    "    description = \"The main program\",\n",
    ")\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"document_search\",\n",
    "    purpose = \"Find relevant documents\",\n",
    "    tool = \"DocumentSearch\",\n",
    "    prompt = \"Please infer the similarity search query (only ONE item) based on the Objective's question\",\n",
    "))\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"answer\",\n",
    "    purpose = \"Answer the Objective's question\",\n",
    "    tool = \"Speak\",\n",
    "    prompt = \"\"\"\n",
    "Please answer the Objective's question using the relevant documents in your context.\n",
    "If no document are relevant just say that you don't know.\n",
    "Don't state the Objective's question and only give the correct answer.\n",
    "\"\"\",\n",
    "))\n",
    "\n",
    "main.connect(\"start\", \"document_search\")\n",
    "main.connect(\"document_search\", \"answer\")\n",
    "main.connect(\"answer\", \"end\")\n",
    "\n",
    "main.build() # Verify that the graph program is correct\n",
    "\n",
    "print(main) # Let's look at it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can add this program into memory\n",
    "\n",
    "from hybridagi.memory.integration.local import LocalProgramMemory\n",
    "\n",
    "program_memory = LocalProgramMemory(index_name=\"vector_rag_agent\")\n",
    "\n",
    "program_memory.update(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m --- Step 0 ---\n",
      "Call Program: main\n",
      "Program Purpose: What are the core knowledge?\u001b[0m\n",
      "\u001b[36m --- Step 1 ---\n",
      "Action Purpose: Find relevant documents\n",
      "Action: {\n",
      "  \"query\": \"core knowledge OR fundamental concepts OR basic principles OR key ideas OR essential facts\",\n",
      "  \"documents\": [\n",
      "    {\n",
      "      \"text\": \"and its research bears on these questions. We believe its\\nresearch has shown that both these views are false: humans\\nare endowed neither with a single, general-purpose learning\\nsystem nor with myriad special-purpose systems and\\npredispositions. Instead, we believe that humans are\\nendowed with a small number of separable systems of\\ncore knowledge. New, \\ufb02exible skills and belief systems\\nbuild on these core foundations.\\nStudies of human infants and non-human animals,\\nfocused on the ontogenetic and phylogenetic origins of\\nknowledge, provide evidence for four core knowledge\\nsystems (Spelke, 2004). These systems serve to represent\\ninanimate objects and their mechanical interactions,\",\n",
      "      \"metadata\": {\n",
      "        \"filepath\": \"data/SpelkeKinzlerCoreKnowledge.pdf\",\n",
      "        \"page\": 0\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Core\\nrepresentations of number support preschool children\\u2019s\\nmastery of counting (Wynn, 1990; Carey, 2001; Spelke,\\n2003) and older children\\u2019s and adults\\u2019 learning and\\nperformance of symbolic arithmetic (Dehaene, 1997;\\nFeigenson, Dehaene & Spelke, 2004). Finally, a core sys-\\ntem for representing potential social partners may guide\\ninfants\\u2019 and children\\u2019s \\u2018cultural learning\\u2019 (Tomasello, 1999):\\ntheir acquisition of skills and behaviors that sustain life\\nwithin a particular human group. In all these cases, core\\nknowledge systems may support and advance human\\ncognitive development,\",\n",
      "      \"metadata\": {\n",
      "        \"filepath\": \"data/SpelkeKinzlerCoreKnowledge.pdf\",\n",
      "        \"page\": 3\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Core knowledge\\n93\\n\\u00a9 2007 The Authors. Journal compilation \\u00a9 2007 Blackwell Publishing Ltd.\\ndiscovered numbers beyond the reach of the core domains,\\nand astute social observers \\ufb01nd many cases where human\\nintentions depart, either deliberately or inadvertently, from\\ntheir overt, goal-directed actions. The gaps and inaccuracies\\nin core representations cause problems for adults and\\nchildren alike, who are prone to errors in reasoning about\\nproperties of object mechanics, non-Euclidean geometry,\\nor numbers that violate the principles of core knowledge\\n(e.g. McCloskey, 1983; Randall, 2005; Gelman, 1991).\",\n",
      "      \"metadata\": {\n",
      "        \"filepath\": \"data/SpelkeKinzlerCoreKnowledge.pdf\",\n",
      "        \"page\": 4\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Mirroring behavior and neural activity occurs in human\\nadults as well (Iacoboni, Woods, Brass, Bekkering,\\nMazziotta & Rizzolatti, 1999), and representations of goal-\\ndirected action guide adults\\u2019 intuitive moral reasoning\\n(Cushman, Young & Hauser, in press). Together, these\\nfindings provide evidence for a core system of agent\\nrepresentation that is evolutionarily ancient and that\\npersists over human development.\\nThe core number system is structured around principles\\nthat contrast with both the object and the agent systems,\\nand it shows its own distinctive signature limits.\",\n",
      "      \"metadata\": {\n",
      "        \"filepath\": \"data/SpelkeKinzlerCoreKnowledge.pdf\",\n",
      "        \"page\": 1\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"by exercising more speci\\ufb01c cognitive\\nsystems with signature properties and limits. The human\\nmind also does not appear to be a \\u2018massively modular\\u2019\\ncollection of hundreds or thousands of special-purpose\\ncognitive devices (Fodor, 2000). Rather, the mind appears\\nto be built on a small number of core systems, including\\nthe four systems just described.\\nAre there other core knowledge systems, with roots in\\nour evolutionary past, that emerge in infancy and serve\\nas foundations for learning and reasoning by children\\nand adults? Recently, we have begun to investigate a \\ufb01fth\\ncandidate system,\",\n",
      "      \"metadata\": {\n",
      "        \"filepath\": \"data/SpelkeKinzlerCoreKnowledge.pdf\",\n",
      "        \"page\": 2\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\u001b[0m\n",
      "\u001b[36m --- Step 2 ---\n",
      "Action Purpose: Answer the Objective's question\n",
      "Action: {\n",
      "  \"message\": \"The four core knowledge systems proposed by Spelke & Kinzler (2007) are:\\n1. Object mechanics system\\n2. Physical space system\\n3. Agent system\\n4. Core number system\\n\\nReference(s): data/SpelkeKinzlerCoreKnowledge.pdf\"\n",
      "}\u001b[0m\n",
      "\u001b[35m --- Step 3 ---\n",
      "End Program: main\u001b[0m\n",
      "The four core knowledge systems proposed by Spelke & Kinzler (2007) are:\n",
      "1. Object mechanics system\n",
      "2. Physical space system\n",
      "3. Agent system\n",
      "4. Core number system\n",
      "\n",
      "Reference(s): data/SpelkeKinzlerCoreKnowledge.pdf\n"
     ]
    }
   ],
   "source": [
    "# Then instanciate our tools and agent system\n",
    "\n",
    "import dspy\n",
    "from hybridagi.core.datatypes import AgentState, Query\n",
    "from hybridagi.modules.agents import GraphInterpreterAgent\n",
    "from hybridagi.modules.retrievers.integration.local import FAISSDocumentRetriever\n",
    "from hybridagi.modules.agents.tools import (\n",
    "    SpeakTool,\n",
    "    DocumentSearchTool,\n",
    ")\n",
    "\n",
    "agent_state = AgentState()\n",
    "\n",
    "tools = [\n",
    "    SpeakTool(\n",
    "        agent_state = agent_state\n",
    "    ),\n",
    "    DocumentSearchTool(\n",
    "        retriever = FAISSDocumentRetriever(\n",
    "            document_memory = document_memory,\n",
    "            embeddings = embeddings,\n",
    "            distance = \"cosine\",\n",
    "            max_distance = 0.7,\n",
    "            k = 5,\n",
    "            reranker = None,\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "rag_agent = GraphInterpreterAgent(\n",
    "    program_memory = program_memory,\n",
    "    agent_state = agent_state,\n",
    "    tools = tools,\n",
    ")\n",
    "\n",
    "# We can now setup the LLM using Ollama client from DSPy\n",
    "\n",
    "lm = dspy.OllamaLocal(model='mistral', max_tokens=1024, stop=[\"\\n\\n\\n\"])\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# And call our agent\n",
    "\n",
    "result = rag_agent(Query(query=\"What are the core knowledge?\"))\n",
    "\n",
    "print(result.final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybridagi-B1GoJrSC-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
