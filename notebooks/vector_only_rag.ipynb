{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Only RAG\n",
    "\n",
    "In this notebook we are going to explore how to make a vector only RAG system using the `DocumentMemory`. RAG stands for Retrieval Augmented Generation, the basic idea of this technique is to not use the LLM to recall knowledge but instead rely on a external system like a database to provide information to the system.\n",
    "\n",
    "The main advantage of vector-only RAG systems over Graph RAG is the fact that you don't need to model your knowledge and can use very simple data pipelines. They excel in retrieving information based on the context of the question but fail short in retrieving factual knowledge (you've been warned).\n",
    "\n",
    "In this tutorial we are going to present you a small system that is nice to learn how RAG works in practice. To make things bit more complicated, we are going to start from the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoan/.cache/pypoetry/virtualenvs/hybridagi-B1GoJrSC-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pymupdf # Used to extract the text from our PDF\n",
    "from hybridagi.core.datatypes import Document, DocumentList\n",
    "from hybridagi.core.pipeline import Pipeline\n",
    "from hybridagi.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from hybridagi.modules.splitters.document_sentence_splitter import DocumentSentenceSplitter\n",
    "from hybridagi.modules.embedders.document_embedder import DocumentEmbedder\n",
    "\n",
    "filename = \"data/SpelkeKinzlerCoreKnowledge.pdf\"\n",
    "pdf_document = pymupdf.open(filename)\n",
    "\n",
    "input_docs = DocumentList()\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(\n",
    "    model_name_or_path = \"all-MiniLM-L6-v2\",\n",
    "    dim = 386, # The dimention of the embeddings vector (also called dense vector)\n",
    ")\n",
    "# We are going to create a full document that have all the pages\n",
    "# With the increase of LLM context windows nowadays, this can be helpfull\n",
    "full_document = Document(text=\"\", metadata={\"filename\": filename})\n",
    "for page_nb, page in enumerate(pdf_document): # iterate over the document pages\n",
    "    text = page.get_text()\n",
    "    full_document.text += text\n",
    "    input_docs.docs.append(Document(\n",
    "        text=text,\n",
    "        metadata={\"filename\": filename, \"page\": page_nb},\n",
    "        parent_id=full_document.id))\n",
    "\n",
    "# Now that we have our input documents, we can start to make our data processing pipeline\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "pipeline.add(\"chunk_documents\", DocumentSentenceSplitter())\n",
    "pipeline.add(\"embed_chunks\", DocumentEmbedder(embeddings=embeddings))\n",
    "\n",
    "output_docs = pipeline(input_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the documents into memory\n",
    "\n",
    "Now that we have our documents we can load them into memory, for storing unstructured textual documents, we provide the `DocumentMemory` and for this example we are going to use the local integration for rapid prototyping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple_rag_document_memory.html\n"
     ]
    }
   ],
   "source": [
    "from hybridagi.memory.integration.local import LocalDocumentMemory\n",
    "\n",
    "document_memory = LocalDocumentMemory(index_name=\"simple_rag\")\n",
    "\n",
    "document_memory.update(full_document)\n",
    "document_memory.update(input_docs)\n",
    "document_memory.update(output_docs)\n",
    "\n",
    "document_memory.show() # Let's see what the memory look like now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving the document chunks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybridagi-B1GoJrSC-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
