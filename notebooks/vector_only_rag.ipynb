{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Only RAG\n",
    "\n",
    "In this notebook we are going to explore how to make a vector only RAG system. RAG stands for Retrieval Augmented Generation, the basic idea of this technique is to not use the LLM to recall knowledge but instead rely on a external system like a database to provide information to the system.\n",
    "\n",
    "The main advantage of vector-only RAG systems over Knowledge Graph RAG is the fact that you don't need to model your knowledge domain and can use very simple data pipelines. They excel in retrieving information based on the context of the question but fail short in retrieving factual knowledge (you've been warned).\n",
    "\n",
    "In this tutorial we are going to present you a small system that is nice to learn how RAG works in practice. To make things bit more complicated, we are going to start from a PDF file.\n",
    "\n",
    "The PDF we are going to parse is a paper from [Elisabeth Spelke](https://en.wikipedia.org/wiki/Elizabeth_Spelke) a developmental psychologist that studied cognition in infants, culturally different communities and non-human species to understand the fundamental building blocks of our mind. It contains evidences that our cognition system is build upon several key components and is an important inspiration for Neuro-Symbolic and Robotics systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoan/.cache/pypoetry/virtualenvs/hybridagi-B1GoJrSC-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 8/8 [00:00<00:00, 1544.79it/s]\n",
      "100%|██████████| 78/78 [00:01<00:00, 42.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import pymupdf # Used to extract the text data from the PDF file\n",
    "from hybridagi.core.datatypes import Document, DocumentList\n",
    "from hybridagi.core.pipeline import Pipeline\n",
    "from hybridagi.embeddings import SentenceTransformerEmbeddings\n",
    "from hybridagi.modules.splitters import DocumentSentenceSplitter\n",
    "from hybridagi.modules.embedders import DocumentEmbedder\n",
    "from hybridagi.readers import PDFReader\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(\n",
    "    model_name_or_path = \"all-MiniLM-L6-v2\",\n",
    "    dim = 384, # The dimention of the embeddings vector (also called dense vector)\n",
    ")\n",
    "\n",
    "reader = PDFReader()\n",
    "\n",
    "input_docs = reader(\"data/SpelkeKinzlerCoreKnowledge.pdf\")\n",
    "\n",
    "# Now that we have our input documents, we can start to make our data processing pipeline\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "pipeline.add(\"chunk_documents\", DocumentSentenceSplitter(\n",
    "    method = \"word\",\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 0,\n",
    "))\n",
    "pipeline.add(\"embed_chunks\", DocumentEmbedder(embeddings=embeddings))\n",
    "\n",
    "output_docs = pipeline(input_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the documents into memory\n",
    "\n",
    "Now that we have our documents we can load them into memory, for storing unstructured textual documents, we provide the `DocumentMemory` and for this example we are going to use the local integration for rapid prototyping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_rag_agent_document_memory.html\n"
     ]
    }
   ],
   "source": [
    "from hybridagi.memory.integration.local import LocalDocumentMemory\n",
    "\n",
    "document_memory = LocalDocumentMemory(index_name=\"vector_rag_agent\")\n",
    "\n",
    "document_memory.update(input_docs)\n",
    "document_memory.update(output_docs)\n",
    "\n",
    "document_memory.show() # Let's see what the memory look like now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a RAG Agent\n",
    "\n",
    "Now that our data is ready and loaded into memory, we can start making our RAG Agent, but first we need to create our graph program that is going to encode the Agent behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// @desc: The main program\n",
      "CREATE\n",
      "// Nodes declaration\n",
      "(start:Control {id: \"start\"}),\n",
      "(end:Control {id: \"end\"}),\n",
      "(document_search:Action {\n",
      "  id: \"document_search\",\n",
      "  purpose: \"Find relevant documents\",\n",
      "  tool: \"DocumentSearch\",\n",
      "  prompt: \"Please infer the similarity search query (only ONE item) based on the Objective's question\"\n",
      "}),\n",
      "(answer:Action {\n",
      "  id: \"answer\",\n",
      "  purpose: \"Answer the Objective's question\",\n",
      "  tool: \"Speak\",\n",
      "  prompt: \"\\nPlease answer the Objective's question using the relevant documents in your context.\\nIf no document are relevant just say that you don't know.\\nDon't state the Objective's question and only give the correct answer.\\n\"\n",
      "}),\n",
      "// Structure declaration\n",
      "(start)-[:NEXT]->(document_search),\n",
      "(document_search)-[:NEXT]->(answer),\n",
      "(answer)-[:NEXT]->(end)\n"
     ]
    }
   ],
   "source": [
    "import hybridagi.core.graph_program as gp\n",
    "\n",
    "# We first need to program our RAG Agent using Graph Prompt Programs\n",
    "# Here we a simple program that involve 2 steps\n",
    "# We first retrieve documents, then answer to the objective's question based on them\n",
    "\n",
    "main = gp.GraphProgram(\n",
    "    name = \"main\",\n",
    "    description = \"The main program\",\n",
    ")\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"document_search\",\n",
    "    purpose = \"Find relevant documents\",\n",
    "    tool = \"DocumentSearch\",\n",
    "    prompt = \"Please infer the similarity search query (only ONE item) based on the Objective's question\",\n",
    "))\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"answer\",\n",
    "    purpose = \"Answer the Objective's question\",\n",
    "    tool = \"Speak\",\n",
    "    prompt = \"\"\"\n",
    "Please answer the Objective's question using the relevant documents in your context.\n",
    "If no document are relevant just say that you don't know.\n",
    "Don't state the Objective's question and only give the correct answer.\n",
    "\"\"\",\n",
    "))\n",
    "\n",
    "main.connect(\"start\", \"document_search\")\n",
    "main.connect(\"document_search\", \"answer\")\n",
    "main.connect(\"answer\", \"end\")\n",
    "\n",
    "main.build() # Verify that the graph program is correct\n",
    "\n",
    "print(main) # Let's look at it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can add this program into memory\n",
    "\n",
    "from hybridagi.memory.integration.local import LocalProgramMemory\n",
    "\n",
    "program_memory = LocalProgramMemory(index_name=\"vector_rag_agent\")\n",
    "\n",
    "program_memory.update(main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m--- Step 0 ---\n",
      "Call Program: main\n",
      "Program Purpose: What are the core knowledge?\u001b[0m\n",
      "\u001b[36m--- Step 1 ---\n",
      "Action Purpose: Find relevant documents\n",
      "Action: {\n",
      "  \"query\": \"core knowledge OR fundamental concepts OR basic principles OR key ideas OR essential facts\",\n",
      "  \"documents\": [\n",
      "    {\n",
      "      \"text\": \"Core knowledge\\n93\\n\\u00a9 2007 The Authors. Journal compilation \\u00a9 2007 Blackwell Publishing Ltd.\\ndiscovered numbers beyond the reach of the core domains,\\nand astute social observers \\ufb01nd many cases where human\\nintentions depart, either deliberately or inadvertently, from\\ntheir overt, goal-directed actions. The gaps and inaccuracies\\nin core representations cause problems for adults and\\nchildren alike, who are prone to errors in reasoning about\\nproperties of object mechanics, non-Euclidean geometry,\\nor numbers that violate the principles of core knowledge\\n(e.g. McCloskey, 1983; Randall, 2005; Gelman, 1991).\",\n",
      "      \"metadata\": {\n",
      "        \"filepath\": \"data/SpelkeKinzlerCoreKnowledge.pdf\",\n",
      "        \"page\": 4\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"and its research bears on these questions. We believe its\\nresearch has shown that both these views are false: humans\\nare endowed neither with a single, general-purpose learning\\nsystem nor with myriad special-purpose systems and\\npredispositions. Instead, we believe that humans are\\nendowed with a small number of separable systems of\\ncore knowledge. New, \\ufb02exible skills and belief systems\\nbuild on these core foundations.\\nStudies of human infants and non-human animals,\\nfocused on the ontogenetic and phylogenetic origins of\\nknowledge, provide evidence for four core knowledge\\nsystems (Spelke, 2004). These systems serve to represent\\ninanimate objects and their mechanical interactions,\",\n",
      "      \"metadata\": {\n",
      "        \"filepath\": \"data/SpelkeKinzlerCoreKnowledge.pdf\",\n",
      "        \"page\": 0\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"by exercising more speci\\ufb01c cognitive\\nsystems with signature properties and limits. The human\\nmind also does not appear to be a \\u2018massively modular\\u2019\\ncollection of hundreds or thousands of special-purpose\\ncognitive devices (Fodor, 2000). Rather, the mind appears\\nto be built on a small number of core systems, including\\nthe four systems just described.\\nAre there other core knowledge systems, with roots in\\nour evolutionary past, that emerge in infancy and serve\\nas foundations for learning and reasoning by children\\nand adults? Recently, we have begun to investigate a \\ufb01fth\\ncandidate system,\",\n",
      "      \"metadata\": {\n",
      "        \"filepath\": \"data/SpelkeKinzlerCoreKnowledge.pdf\",\n",
      "        \"page\": 2\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Simons & Levin, 1998; Lavin & Hall, 2001;\\nSantos, Hauser & Spelke, 2001). When attentional resources\\nare stretched, however, the properties that mark these\\n\\ufb01ner distinctions often fail to guide object representa-\\ntions, whereas core properties continue to do so (Leslie,\\nXu, Tremoulet & Scholl, 1998).\\nIf the core system of object representation is constant\\nover human development, then one would expect that\\nsystem to be universal. Recent studies of the Piraha, a\\nremote Amazonian group, support that suggestion.\",\n",
      "      \"metadata\": {\n",
      "        \"filepath\": \"data/SpelkeKinzlerCoreKnowledge.pdf\",\n",
      "        \"page\": 1\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"because the principles on which\\nthey are based are veridical and adaptive at the scales at\\nwhich humans and other animals perceive and act on the\\nworld.\\nNevertheless, core systems of representation also can\\nlead humans into cognitive errors and maladaptive actions.\\nAt the smallest and largest scales that science can probe,\\nobjects are not cohesive or continuous, and space is\\nnot Euclidean or three-dimensional. Mathematicians have\",\n",
      "      \"metadata\": {\n",
      "        \"filepath\": \"data/SpelkeKinzlerCoreKnowledge.pdf\",\n",
      "        \"page\": 3\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\u001b[0m\n",
      "\u001b[36m--- Step 2 ---\n",
      "Action Purpose: Answer the Objective's question\n",
      "Action: {\n",
      "  \"message\": \"The four core knowledge systems proposed by Spelke (2004) are:\\n1. Representation of inanimate objects and their mechanical interactions.\\n2. Representation of animate agents and their goals, actions, and intentions.\\n3. Representation of number and quantity.\\n4. Representation of space and spatial relationships.\"\n",
      "}\u001b[0m\n",
      "\u001b[35m--- Step 3 ---\n",
      "End Program: main\u001b[0m\n",
      "The four core knowledge systems proposed by Spelke (2004) are:\n",
      "1. Representation of inanimate objects and their mechanical interactions.\n",
      "2. Representation of animate agents and their goals, actions, and intentions.\n",
      "3. Representation of number and quantity.\n",
      "4. Representation of space and spatial relationships.\n"
     ]
    }
   ],
   "source": [
    "# Then instanciate our tools and agent system\n",
    "\n",
    "import dspy\n",
    "from hybridagi.core.datatypes import AgentState, Query\n",
    "from hybridagi.modules.agents import GraphInterpreterAgent\n",
    "from hybridagi.modules.retrievers.integration.local import FAISSDocumentRetriever\n",
    "from hybridagi.modules.agents.tools import (\n",
    "    SpeakTool,\n",
    "    DocumentSearchTool,\n",
    ")\n",
    "\n",
    "agent_state = AgentState()\n",
    "\n",
    "tools = [\n",
    "    SpeakTool(\n",
    "        agent_state = agent_state\n",
    "    ),\n",
    "    DocumentSearchTool(\n",
    "        retriever = FAISSDocumentRetriever(\n",
    "            document_memory = document_memory,\n",
    "            embeddings = embeddings,\n",
    "            distance = \"cosine\",\n",
    "            max_distance = 0.7,\n",
    "            k = 5,\n",
    "            reranker = None,\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "rag_agent = GraphInterpreterAgent(\n",
    "    program_memory = program_memory,\n",
    "    agent_state = agent_state,\n",
    "    tools = tools,\n",
    ")\n",
    "\n",
    "# We can now setup the LLM using Ollama client from DSPy\n",
    "\n",
    "lm = dspy.OllamaLocal(model='mistral', max_tokens=1024, stop=[\"\\n\\n\\n\"])\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# And call our agent\n",
    "\n",
    "result = rag_agent(Query(query=\"What are the core knowledge?\"))\n",
    "\n",
    "print(result.final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybridagi-B1GoJrSC-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
