{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating the Document Memory (on the fly)\n",
    "\n",
    "To be able to learn our Agent system needs to be able to modify its memory on the fly. This feature particularly important in any learning system is often not present in Agent systems. Because actually integrating new documents or facts into memory include also the data processing pipeline needed to chunk/extract and embed the information.\n",
    "\n",
    "With HybridAGI, we have a very elegant way of doing it by using on the fly data processing pipelines. Allowing the Agent to learn on the fly new knowledge. However this technique should not replace the traditional way of integrating prior knowledge to the system like presented in other notebooks, that is two different kind of applications. This way of populating the memory should be only used when working with an Agent system that needs to learn, or if you are building a scrapper Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoan/.cache/pypoetry/virtualenvs/hybridagi-B1GoJrSC-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import hybridagi.core.graph_program as gp\n",
    "\n",
    "main = gp.GraphProgram(\n",
    "    name = \"main\",\n",
    "    description = \"The main program\",\n",
    ")\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"search_docs\",\n",
    "    purpose = \"Search for relevant documents to answer the Objective's question\",\n",
    "    tool = \"DocumentSearch\",\n",
    "    prompt = \"Please use the Objective's question to infer the search query\",\n",
    "))\n",
    "\n",
    "main.add(gp.Decision(\n",
    "    id = \"check_context\",\n",
    "    purpose = \"Check if the answer to the Objective's question is in your Context\",\n",
    "    question = \"Is the answer to the Objective's question in your context?\"\n",
    "))\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"answer_context_based\",\n",
    "    purpose = \"Answer to the Objective's question based on your Context\",\n",
    "    tool = \"Speak\",\n",
    "    prompt = \"Answer to the Objective's question, if there is relevant information in your Context, please use it\",\n",
    "))\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"answer\",\n",
    "    purpose = \"Answer to the Objective's question\",\n",
    "    tool = \"Speak\",\n",
    "    prompt = \"Answer to the Objective's question, don't say it is based on your search just answer\",\n",
    "))\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"save_answer\",\n",
    "    purpose = \"Save the answer to the Objective question into memory\",\n",
    "    tool = \"AddDocument\",\n",
    "    prompt = \"Use the answer in your context to infer the document to save, never explain what you are doing\",\n",
    "))\n",
    "\n",
    "main.connect(\"start\", \"search_docs\")\n",
    "main.connect(\"search_docs\", \"check_context\")\n",
    "main.connect(\"check_context\", \"answer_context_based\", label=\"Yes\")\n",
    "main.connect(\"check_context\", \"answer\", label=\"No\")\n",
    "main.connect(\"answer\", \"save_answer\")\n",
    "main.connect(\"answer_context_based\", \"end\")\n",
    "main.connect(\"save_answer\", \"end\")\n",
    "\n",
    "main.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the programs into memory\n",
    "from hybridagi.memory.integration.local import LocalProgramMemory, LocalDocumentMemory\n",
    "\n",
    "program_memory = LocalProgramMemory(index_name=\"update_memory\")\n",
    "\n",
    "program_memory.update(main)\n",
    "\n",
    "# Then we instanciate the document memory for later use\n",
    "\n",
    "document_memory = LocalDocumentMemory(index_name=\"update_memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we setup the agent and tools\n",
    "import dspy\n",
    "from hybridagi.core.datatypes import AgentState\n",
    "from hybridagi.core.pipeline import Pipeline\n",
    "from hybridagi.embeddings import SentenceTransformerEmbeddings\n",
    "from hybridagi.modules.agents import GraphInterpreterAgent\n",
    "from hybridagi.modules.splitters import DocumentSentenceSplitter\n",
    "from hybridagi.modules.embedders import DocumentEmbedder\n",
    "from hybridagi.modules.retrievers.integration.local import FAISSDocumentRetriever \n",
    "from hybridagi.modules.agents.tools import (\n",
    "    SpeakTool,\n",
    "    DocumentSearchTool,\n",
    "    AddDocumentTool,\n",
    ")\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(\n",
    "    model_name_or_path = \"all-MiniLM-L6-v2\",\n",
    "    dim = 384,\n",
    ")\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "pipeline.add(\"chunk_documents\", DocumentSentenceSplitter(\n",
    "    method = \"word\",\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 0,\n",
    "))\n",
    "pipeline.add(\"embed_chunks\", DocumentEmbedder(embeddings=embeddings))\n",
    "\n",
    "agent_state = AgentState()\n",
    "\n",
    "tools = [\n",
    "    SpeakTool(\n",
    "        agent_state = agent_state,\n",
    "    ),\n",
    "    DocumentSearchTool(\n",
    "        retriever = FAISSDocumentRetriever(\n",
    "            document_memory = document_memory,\n",
    "            embeddings = embeddings,\n",
    "            distance = \"cosine\",\n",
    "            max_distance = 1.0,\n",
    "            k = 5,\n",
    "            reranker = None,\n",
    "        ),\n",
    "    ),\n",
    "    AddDocumentTool(\n",
    "        document_memory = document_memory,\n",
    "        pipeline = pipeline # Here we bind the document processing pipeline to our tool\n",
    "    ),\n",
    "]\n",
    "\n",
    "lm = dspy.OllamaLocal(model='mistral', max_tokens=1024, stop=[\"\\n\\n\\n\"])\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "agent = GraphInterpreterAgent(\n",
    "    program_memory = program_memory,\n",
    "    agent_state = agent_state,\n",
    "    tools = tools,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m--- Step 0 ---\n",
      "Call Program: main\n",
      "Program Purpose: What the definition of a neuro symbolic AI\u001b[0m\n",
      "\u001b[36m--- Step 1 ---\n",
      "Action Purpose: Search for relevant documents to answer the Objective's question\n",
      "Action: {\n",
      "  \"query\": \"definition of neuro symbolic AI\",\n",
      "  \"documents\": []\n",
      "}\u001b[0m\n",
      "\u001b[34m--- Step 2 ---\n",
      "Decision Purpose: Check if the answer to the Objective's question is in your Context\n",
      "Decision Question: Is the answer to the Objective's question in your context?\n",
      "Decision: NO\u001b[0m\n",
      "\u001b[36m--- Step 3 ---\n",
      "Action Purpose: Answer to the Objective's question\n",
      "Action: {\n",
      "  \"message\": \"A neuro-symbolic AI is a type of artificial intelligence that combines symbolic reasoning and neural networks. It aims to bridge the gap between traditional rule-based systems (symbolic) and learning-based systems (neural networks). This integration allows the model to understand, reason, and learn from complex data in a more human-like manner.\"\n",
      "}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 11275.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m--- Step 4 ---\n",
      "Action Purpose: Save the answer to the Objective Question into memory\n",
      "Action: {\n",
      "  \"documents\": [\n",
      "    {\n",
      "      \"text\": \"A neuro-symbolic AI is a type of artificial intelligence that combines symbolic reasoning and neural networks. It aims to bridge the gap between traditional rule-based systems (symbolic) and learning-based systems (neural networks). This integration allows the model to understand, reason, and learn from complex data in a more human-like manner.\",\n",
      "      \"metadata\": {}\n",
      "    }\n",
      "  ]\n",
      "}\u001b[0m\n",
      "\u001b[35m--- Step 5 ---\n",
      "End Program: main\u001b[0m\n",
      "A neuro-symbolic AI is a type of artificial intelligence that combines symbolic reasoning and neural networks. It aims to bridge the gap between traditional rule-based systems (symbolic) and learning-based systems (neural networks). This integration allows the model to understand, reason, and learn from complex data in a more human-like manner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from hybridagi.core.datatypes import Query\n",
    "\n",
    "# Now we can test our system\n",
    "result = agent(Query(query=\"What the definition of a neuro symbolic AI\"))\n",
    "\n",
    "print(result.final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m--- Step 0 ---\n",
      "Call Program: main\n",
      "Program Purpose: What the definition of a neuro symbolic AI\u001b[0m\n",
      "\u001b[36m--- Step 1 ---\n",
      "Action Purpose: Search for relevant documents to answer the Objective's question\n",
      "Action: {\n",
      "  \"query\": \"definition of neuro symbolic AI\",\n",
      "  \"documents\": [\n",
      "    {\n",
      "      \"text\": \"A neuro-symbolic AI is a type of artificial intelligence that combines symbolic reasoning and neural networks. It aims to bridge the gap between traditional rule-based systems (symbolic) and learning-based systems (neural networks). This integration allows the model to understand, reason, and learn from complex data in a more human-like manner.\",\n",
      "      \"metadata\": {}\n",
      "    }\n",
      "  ]\n",
      "}\u001b[0m\n",
      "\u001b[34m--- Step 2 ---\n",
      "Decision Purpose: Check if the answer to the Objective's question is in your Context\n",
      "Decision Question: Is the answer to the Objective's question in your context?\n",
      "Decision: YES\u001b[0m\n",
      "\u001b[36m--- Step 3 ---\n",
      "Action Purpose: Answer to the Objective's question based on your Context\n",
      "Action: {\n",
      "  \"message\": \"The definition of a neuro-symbolic AI is as follows: A neuro-symbolic AI is a type of artificial intelligence that combines symbolic reasoning and neural networks. It aims to bridge the gap between traditional rule-based systems (symbolic) and learning-based systems (neural networks). This integration allows the model to understand, reason, and learn from complex data in a more human-like manner.\"\n",
      "}\u001b[0m\n",
      "\u001b[35m--- Step 4 ---\n",
      "End Program: main\u001b[0m\n",
      "The definition of a neuro-symbolic AI is as follows: A neuro-symbolic AI is a type of artificial intelligence that combines symbolic reasoning and neural networks. It aims to bridge the gap between traditional rule-based systems (symbolic) and learning-based systems (neural networks). This integration allows the model to understand, reason, and learn from complex data in a more human-like manner.\n"
     ]
    }
   ],
   "source": [
    "# Ok so now we can actually try to run the agent again to see if the memory got updated correctly\n",
    "\n",
    "result = agent(Query(query=\"What the definition of a neuro symbolic AI\"))\n",
    "\n",
    "print(result.final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybridagi-B1GoJrSC-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
