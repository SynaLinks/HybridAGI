{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episodic Memory RAG\n",
    "\n",
    "The episodic memory is a type of long-term memory that allows us to remember specific events or experiences in our lives. Unlike the declarative memory, which stores general knowledge and facts, the episodic memory is more focused on personal experiences and the context in which they occurred.\n",
    "\n",
    "In the context of HybridAGI we wanted to ground this concept into Computer Sciences, and what best representation than a memory that store the program traces?\n",
    "\n",
    "In HybridAGI's Trace Memory, each action is vectorized and stored, so the system can retrieve past actions between sessions by using the `PastActionSearch` tool.\n",
    "\n",
    "Note: To avoid recursive recall of memories, we don't vectorize the `PastActionSearch` actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoan/.cache/pypoetry/virtualenvs/hybridagi-B1GoJrSC-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// @desc: The main program\n",
      "CREATE\n",
      "// Nodes declaration\n",
      "(start:Control {id: \"start\"}),\n",
      "(end:Control {id: \"end\"}),\n",
      "(action_search:Action {\n",
      "  id: \"action_search\",\n",
      "  purpose: \"Search for past steps to answer the Objective's question\",\n",
      "  tool: \"PastActionSearch\",\n",
      "  prompt: \"Use the Objective's question to infer the search query\"\n",
      "}),\n",
      "(is_search_relevant:Decision {\n",
      "  id: \"is_search_relevant\",\n",
      "  purpose: \"Check if the answer is contained in the context\",\n",
      "  question: \"Is the answer to the Objective's question in the context steps?\"\n",
      "}),\n",
      "(answer_context_based:Action {\n",
      "  id: \"answer_context_based\",\n",
      "  purpose: \"Answer the Objective's question\",\n",
      "  tool: \"Speak\",\n",
      "  prompt: \"Answer the Objective's question based on the previous steps in the context\"\n",
      "}),\n",
      "(answer:Action {\n",
      "  id: \"answer\",\n",
      "  purpose: \"Answer the Objective's question\",\n",
      "  tool: \"Speak\",\n",
      "  prompt: \"Answer the Objective's question based on your own knowledge\"\n",
      "}),\n",
      "// Structure declaration\n",
      "(start)-[:NEXT]->(action_search),\n",
      "(action_search)-[:NEXT]->(is_search_relevant),\n",
      "(is_search_relevant)-[:YES]->(answer_context_based),\n",
      "(is_search_relevant)-[:NO]->(answer),\n",
      "(answer_context_based)-[:NEXT]->(end),\n",
      "(answer)-[:NEXT]->(end)\n"
     ]
    }
   ],
   "source": [
    "import hybridagi.core.graph_program as gp\n",
    "\n",
    "# We first need to program our RAG Agent using a Graph Prompt Program\n",
    "# So, let's create our program\n",
    "\n",
    "main = gp.GraphProgram(\n",
    "    name = \"main\",\n",
    "    description = \"The main program\",\n",
    ")\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"action_search\",\n",
    "    purpose = \"Search for past steps to answer the Objective's question\",\n",
    "    tool = \"PastActionSearch\",\n",
    "    prompt = \"Use the Objective's question to infer the search query\",\n",
    "))\n",
    "\n",
    "main.add(gp.Decision(\n",
    "    id = \"is_search_relevant\",\n",
    "    purpose = \"Check if the answer is contained in the context\",\n",
    "    question = \"Is the answer to the Objective's question in the context steps?\",    \n",
    "))\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"answer_context_based\",\n",
    "    purpose = \"Answer the Objective's question\",\n",
    "    tool = \"Speak\",\n",
    "    prompt = \"Answer the Objective's question based on the previous steps in the context\",\n",
    "))\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"answer\",\n",
    "    purpose = \"Answer the Objective's question\",\n",
    "    tool = \"Speak\",\n",
    "    prompt = \"Answer the Objective's question based on your own knowledge\",\n",
    "))\n",
    "\n",
    "main.connect(\"start\", \"action_search\")\n",
    "main.connect(\"action_search\", \"is_search_relevant\")\n",
    "main.connect(\"is_search_relevant\", \"answer_context_based\", label=\"Yes\")\n",
    "main.connect(\"is_search_relevant\", \"answer\", label=\"Maybe\")\n",
    "main.connect(\"is_search_relevant\", \"answer\", label=\"No\")\n",
    "main.connect(\"answer_context_based\", \"end\")\n",
    "main.connect(\"answer\", \"end\")\n",
    "\n",
    "main.build() # Verify the graph program\n",
    "\n",
    "print(main) # Print it to check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'program_memory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhybridagi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatatypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgentState, Query\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhybridagi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphInterpreterAgent\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhybridagi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegration\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlocal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISSActionRetriever\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhybridagi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformerEmbeddings\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhybridagi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     SpeakTool,\n\u001b[1;32m     11\u001b[0m     PastActionSearchTool,\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/Workspace/HybridAGI/hybridagi/modules/retrievers/integration/local/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfaiss_action_retriever\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISSActionRetriever\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfaiss_fact_retriever\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISSFactRetriever\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfaiss_graph_program_retriever\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISSGraphProgramRetriever\n\u001b[1;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     FAISSDocumentRetriever,\n\u001b[1;32m      9\u001b[0m     FAISSEntityRetriever,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     FAISSGraphProgramRetriever,\n\u001b[1;32m     13\u001b[0m ]\n",
      "File \u001b[0;32m~/Workspace/HybridAGI/hybridagi/modules/retrievers/integration/local/faiss_graph_program_retriever.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m     Cosine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m     Euclidean \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFAISSGraphProgramRetriever\u001b[39;00m(GraphProgramRetriever):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     20\u001b[0m             program_memory: program_memory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m             reranker: Optional[ProgramReranker] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     26\u001b[0m         ):\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogram_memory \u001b[38;5;241m=\u001b[39m program_memory\n",
      "File \u001b[0;32m~/Workspace/HybridAGI/hybridagi/modules/retrievers/integration/local/faiss_graph_program_retriever.py:20\u001b[0m, in \u001b[0;36mFAISSGraphProgramRetriever\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFAISSGraphProgramRetriever\u001b[39;00m(GraphProgramRetriever):\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m---> 20\u001b[0m             program_memory: \u001b[43mprogram_memory\u001b[49m,\n\u001b[1;32m     21\u001b[0m             embeddings: Embeddings,\n\u001b[1;32m     22\u001b[0m             distance: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m             max_distance: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     24\u001b[0m             k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     25\u001b[0m             reranker: Optional[ProgramReranker] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     26\u001b[0m         ):\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogram_memory \u001b[38;5;241m=\u001b[39m program_memory\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;241m=\u001b[39m embeddings\n",
      "\u001b[0;31mNameError\u001b[0m: name 'program_memory' is not defined"
     ]
    }
   ],
   "source": [
    "# Now we can store it into memory and instanciate our agent\n",
    "\n",
    "import dspy\n",
    "from hybridagi.memory.integration.local import LocalProgramMemory, LocalTraceMemory\n",
    "from hybridagi.core.datatypes import AgentState, Query\n",
    "from hybridagi.modules.agents import GraphInterpreterAgent\n",
    "from hybridagi.modules.retrievers.integration.local import FAISSActionRetriever\n",
    "from hybridagi.embeddings import SentenceTransformerEmbeddings\n",
    "from hybridagi.modules.agents.tools import (\n",
    "    SpeakTool,\n",
    "    PastActionSearchTool,\n",
    ")\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(\n",
    "    model_name_or_path = \"all-MiniLM-L6-v2\",\n",
    "    dim = 384, # The dimention of the embeddings vector (also called dense vector)\n",
    ")\n",
    "\n",
    "program_memory = LocalProgramMemory(index_name=\"episodic_rag\")\n",
    "\n",
    "program_memory.update(main)\n",
    "\n",
    "trace_memory = LocalTraceMemory(index_name=\"episodic_rag\")\n",
    "\n",
    "agent_state = AgentState()\n",
    "\n",
    "tools = [\n",
    "    SpeakTool(\n",
    "        agent_state = agent_state\n",
    "    ),\n",
    "    PastActionSearchTool(\n",
    "        retriever = FAISSActionRetriever(\n",
    "            trace_memory = trace_memory,\n",
    "            embeddings = embeddings,\n",
    "            distance = \"cosine\",\n",
    "            max_distance = 0.9,\n",
    "            k = 5,\n",
    "            reranker = None,\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "rag_agent = GraphInterpreterAgent(\n",
    "    program_memory = program_memory,\n",
    "    trace_memory = trace_memory,\n",
    "    embeddings = embeddings,\n",
    "    agent_state = agent_state,\n",
    "    tools = tools,\n",
    ")\n",
    "\n",
    "# We can now setup the LLM using Ollama client from DSPy\n",
    "\n",
    "lm = dspy.OllamaLocal(model='mistral', max_tokens=1024, stop=[\"\\n\\n\\n\"])\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# And call our agent\n",
    "\n",
    "result = rag_agent(Query(query=\"What is a neuro-symbolic AGI?\"))\n",
    "\n",
    "print(result.final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m --- Step 0 ---\n",
      "Call Program: main\n",
      "Program Purpose: What is the definition of a neuro-symbolic AGI?\u001b[0m\n",
      "\u001b[36m --- Step 1 ---\n",
      "Action Purpose: Search for past steps to answer the Objective's question\n",
      "Action: {\n",
      "  \"query\": \"neuro-symbolic AGI definition\",\n",
      "  \"steps\": [\n",
      "    {\n",
      "      \"step\": \" --- Step 3 ---\\nAction Purpose: Answer the Objective's question\\nAction: {\\n  \\\"message\\\": \\\"A neuro-symbolic AGI, or Artificial General Intelligence, is a type of artificial intelligence that combines both neural networks (neuro) and symbolic reasoning (symbolic). This integration allows the AI to learn from data (as neural networks do) and reason about that knowledge using symbols and logic (as humans do). The goal is to create an AGI that can understand, learn, and apply knowledge in a general and flexible manner, similar to how humans think.\\\"\\n}\"\n",
      "    }\n",
      "  ]\n",
      "}\u001b[0m\n",
      "\u001b[34m --- Step 2 ---\n",
      "Decision Purpose: Check if the answer is contained in the context\n",
      "Decision Question: Is the answer to the Objective's question in the context steps?\n",
      "Decision: YES\u001b[0m\n",
      "\u001b[36m --- Step 3 ---\n",
      "Action Purpose: Answer the Objective's question\n",
      "Action: {\n",
      "  \"message\": \"A neuro-symbolic AGI is a type of artificial intelligence that combines both neural networks (neuro) and symbolic reasoning (symbolic). This integration allows the AI to learn from data (as neural networks do) and reason about that knowledge using symbols and logic (as humans do). The goal is to create an AGI that can understand, learn, and apply knowledge in a general and flexible manner, similar to how humans think.\"\n",
      "}\u001b[0m\n",
      "\u001b[35m --- Step 4 ---\n",
      "End Program: main\u001b[0m\n",
      "A neuro-symbolic AGI is a type of artificial intelligence that combines both neural networks (neuro) and symbolic reasoning (symbolic). This integration allows the AI to learn from data (as neural networks do) and reason about that knowledge using symbols and logic (as humans do). The goal is to create an AGI that can understand, learn, and apply knowledge in a general and flexible manner, similar to how humans think.\n"
     ]
    }
   ],
   "source": [
    "result = rag_agent(Query(query=\"What is the definition of a neuro-symbolic AGI?\"))\n",
    "\n",
    "print(result.final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episodic_rag_trace_memory.html\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look at the trace memory\n",
    "\n",
    "trace_memory.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybridagi-B1GoJrSC-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
