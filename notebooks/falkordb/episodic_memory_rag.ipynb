{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episodic Memory RAG\n",
    "\n",
    "The episodic memory is a type of long-term memory that allows us to remember specific events or experiences in our lives. Unlike the declarative memory, which stores general knowledge and facts, the episodic memory is more focused on personal experiences and the context in which they occurred.\n",
    "\n",
    "In the context of HybridAGI we wanted to ground this concept into Computer Sciences, and what best representation than a memory that store the program traces?\n",
    "\n",
    "In HybridAGI's Trace Memory, each action is vectorized and stored, so the system can retrieve past actions between sessions by using the `PastActionSearch` tool.\n",
    "\n",
    "Note: To avoid recursive recall of memories, we don't vectorize the `PastActionSearch` actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hybridagi.core.graph_program as gp\n",
    "\n",
    "# We first need to program our RAG Agent using a Graph Prompt Program\n",
    "# So, let's create our program\n",
    "\n",
    "main = gp.GraphProgram(\n",
    "    name = \"main\",\n",
    "    description = \"The main program\",\n",
    ")\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"action_search\",\n",
    "    purpose = \"Search for past steps to answer the Objective's question\",\n",
    "    tool = \"PastActionSearch\",\n",
    "    prompt = \"Use the Objective's question to infer the search query\",\n",
    "))\n",
    "\n",
    "main.add(gp.Decision(\n",
    "    id = \"is_search_relevant\",\n",
    "    purpose = \"Check if the answer is contained in the context\",\n",
    "    question = \"Is the answer to the Objective's question in the context steps?\",    \n",
    "))\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"answer_context_based\",\n",
    "    purpose = \"Answer the Objective's question\",\n",
    "    tool = \"Speak\",\n",
    "    prompt = \"Answer the Objective's question based on the previous steps in the context\",\n",
    "))\n",
    "\n",
    "main.add(gp.Action(\n",
    "    id = \"answer\",\n",
    "    purpose = \"Answer the Objective's question\",\n",
    "    tool = \"Speak\",\n",
    "    prompt = \"Answer the Objective's question based on your own knowledge\",\n",
    "))\n",
    "\n",
    "main.connect(\"start\", \"action_search\")\n",
    "main.connect(\"action_search\", \"is_search_relevant\")\n",
    "main.connect(\"is_search_relevant\", \"answer_context_based\", label=\"Yes\")\n",
    "main.connect(\"is_search_relevant\", \"answer\", label=\"Maybe\")\n",
    "main.connect(\"is_search_relevant\", \"answer\", label=\"No\")\n",
    "main.connect(\"answer_context_based\", \"end\")\n",
    "main.connect(\"answer\", \"end\")\n",
    "\n",
    "main.build() # Verify the graph program\n",
    "\n",
    "print(main) # Print it to check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can store it into memory and instanciate our agent\n",
    "\n",
    "import dspy\n",
    "from hybridagi.memory.integration.falkordb import FalkorDBProgramMemory, FalkorDBTraceMemory\n",
    "from hybridagi.core.datatypes import AgentState, Query\n",
    "from hybridagi.modules.agents import GraphInterpreterAgent\n",
    "from hybridagi.modules.retrievers.integration.local import FAISSActionRetriever\n",
    "from hybridagi.embeddings import SentenceTransformerEmbeddings\n",
    "from hybridagi.modules.agents.tools import (\n",
    "    SpeakTool,\n",
    "    PastActionSearchTool,\n",
    ")\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(\n",
    "    model_name_or_path = \"all-MiniLM-L6-v2\",\n",
    "    dim = 384, # The dimention of the embeddings vector (also called dense vector)\n",
    ")\n",
    "\n",
    "program_memory = FalkorDBProgramMemory(\n",
    "    index_name=\"episodic_rag\",\n",
    "    embeddings = embeddings\n",
    ")\n",
    "\n",
    "program_memory.update(main)\n",
    "\n",
    "trace_memory = FalkorDBTraceMemory(\n",
    "    index_name=\"episodic_rag\",\n",
    "    embeddings = embeddings\n",
    ")\n",
    "\n",
    "agent_state = AgentState()\n",
    "\n",
    "tools = [\n",
    "    SpeakTool(\n",
    "        agent_state = agent_state\n",
    "    ),\n",
    "    PastActionSearchTool(\n",
    "        retriever = FAISSActionRetriever(\n",
    "            trace_memory = trace_memory,\n",
    "            embeddings = embeddings,\n",
    "            distance = \"cosine\",\n",
    "            max_distance = 0.9,\n",
    "            k = 5,\n",
    "            reranker = None,\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "rag_agent = GraphInterpreterAgent(\n",
    "    program_memory = program_memory,\n",
    "    trace_memory = trace_memory,\n",
    "    embeddings = embeddings,\n",
    "    agent_state = agent_state,\n",
    "    tools = tools,\n",
    ")\n",
    "\n",
    "# We can now setup the LLM using Ollama client from DSPy\n",
    "\n",
    "lm = dspy.OllamaLocal(model='mistral', max_tokens=1024, stop=[\"\\n\\n\\n\"])\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# And call our agent\n",
    "\n",
    "result = rag_agent(Query(query=\"What is a neuro-symbolic AGI?\"))\n",
    "\n",
    "print(result.final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rag_agent(Query(query=\"What is the definition of a neuro-symbolic AGI?\"))\n",
    "\n",
    "print(result.final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybridagi-B1GoJrSC-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
