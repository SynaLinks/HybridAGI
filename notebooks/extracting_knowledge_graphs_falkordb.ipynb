{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Knowledge Graphs with LLMs\n",
    "\n",
    "You can use LLMs to extract graph data in order to create a Knowledge Graph for the system to request. However, if you want to implement Knowledge Graph RAG for business operations, we advise you to create the graph yourself instead of relying on LLMs, they can introduce many noise and it is always better to understand the data you want to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 5801.25it/s]\n",
      "100%|██████████| 4/4 [00:11<00:00,  2.83s/it]\n",
      "100%|██████████| 22/22 [00:00<00:00, 92090.51it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 95.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from hybridagi.readers import TextReader\n",
    "from hybridagi.core.pipeline import Pipeline\n",
    "from hybridagi.embeddings import SentenceTransformerEmbeddings\n",
    "from hybridagi.memory.integration.falkordb import FalkorDBFactMemory\n",
    "from hybridagi.modules.embedders import FactEmbedder\n",
    "from hybridagi.modules.extractors import LLMFactExtractor\n",
    "from hybridagi.modules.deduplicators import EntityDeduplicator\n",
    "from hybridagi.modules.splitters import DocumentSentenceSplitter\n",
    "\n",
    "lm = dspy.OllamaLocal(model='mistral', max_tokens=1024, stop=[\"\\n\\n\\n\", \"\\n---\", \"\\n\\nContext:\"])\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(\n",
    "    model_name_or_path = \"all-MiniLM-L6-v2\",\n",
    "    dim = 384,\n",
    ")\n",
    "\n",
    "reader = TextReader()\n",
    "\n",
    "input_docs = reader(\"data/SynaLinks_presentation.md\")\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "pipeline.add(\"chunk_docs\", DocumentSentenceSplitter(\n",
    "    method = \"word\",\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 0,\n",
    "    separator = \" \",\n",
    "))\n",
    "pipeline.add(\"extract_facts\", LLMFactExtractor())\n",
    "pipeline.add(\"deduplicate_entities\", EntityDeduplicator(method=\"exact\"))\n",
    "pipeline.add(\"embed_facts\", FactEmbedder(embeddings=embeddings))\n",
    "\n",
    "output_facts = pipeline(input_docs)\n",
    "\n",
    "fact_memory = FalkorDBFactMemory(\n",
    "    index_name=\"synalinks_graph\", \n",
    "    graph_index=\"synalinks_graph\",\n",
    "    embeddings=embeddings,\n",
    "    wipe_on_start=True,\n",
    ")\n",
    "\n",
    "fact_memory.update(output_facts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybridagi-B1GoJrSC-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
